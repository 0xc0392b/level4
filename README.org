#+TITLE:  level4
#+AUTHOR: William Santos
#+EMAIL:  w@wsantos.net

#+LANGUAGE: en
#+STARTUP:  showall
#+OPTIONS:  toc:2

ðŸ”¥ Aggregated level2 market data feeds for multiple cryptocurrency
exchanges. Publishes mid-market price change and timesale data to a
Kafka topic

* Features
- 11 exchanges
- multi-node / load-balancing
- gRPC server
- outputs kafka

** Supported exchanges
| Exchange | Spot markets | Futures markets | Inverse futures |
|----------+--------------+-----------------+-----------------|
| Binance  | Yes          | Yes             | Yes             |
|----------+--------------+-----------------+-----------------|
| Bitfinex | Yes          | Yes             | No              |
|----------+--------------+-----------------+-----------------|
| Bitflyer | Yes          | No              | No              |
|----------+--------------+-----------------+-----------------|
| Bitmex   | Yes          | Yes             | No              |
|----------+--------------+-----------------+-----------------|
| Bitstamp | Yes          | No              | No              |
|----------+--------------+-----------------+-----------------|
| Bybit    | Yes          | Yes             | Yes             |
|----------+--------------+-----------------+-----------------|
| Coinbase | Yes          | No              | No              |
|----------+--------------+-----------------+-----------------|
| Gemini   | Yes          | No              | No              |
|----------+--------------+-----------------+-----------------|
| HitBTC   | Yes          | Yes             | No              |
|----------+--------------+-----------------+-----------------|
| Kraken   | Yes          | Yes             | Yes             |
|----------+--------------+-----------------+-----------------|
| Poloniex | Yes          | No              | No              |
|----------+--------------+-----------------+-----------------|

** Kafka
Best bid/ask price changes are published to the Kafka topic
=level4.spread= and buys/sells are published to
=level4.timesales=. The partition is set to the market's numeric
identifier (market ID).

** RPC server
Each node exposes a GRPC server on port =50051= allowing the following
procedures to be called remotely:

- start/stop market data feeds
- list active market data feeds
- list nodes in the cluster

* Architecture
Level4 is designed to run in cluster mode: running nodes in multiple
containers / on different machines. They will discover each other via
the gossip protocol over UDP.

Each node is configured such that it can hots a maximum of =25= data
feeds concurrently. when staring a data feed, a random node in the
cluster is chosen to be the host. *Other load-balancing strategies
might be added in the future*.

If a node fails, the *data feeds are not automatically rescheduled*
elsewhere in the cluster. They must be manually restarted. This
limitation might also be addressed in the future.

** Websockets
...

** Orderbooks
The orderbook is stored in-memory using a general balanced tree data
structure. This allows logarithmic inserts, updates, and deletions,
which is important because a market's orderbook can be updated many
hundreds or thousands of times each second.

Two balanced trees are used: one to store the bids side, and one to
store the asks side. This means the best bid price and be founded by
locating the largest price in the bids tree. The best ask price can
be found by locating the smallest price in the asks tree. Both of
these operations are done in logarithmic time.

The orderbook is initialised using a snapshot, and then updated by
applying individual deltas. The snapshot consists of two lists, both
of the form =[{price, size}, {price, size}, ...]=, which capture the
price levels and associated liquidity for the bids side and the asks
side. A delta is a single message of the form ={price, size}= which
updates the available liquidity for a given price level. If =size= is
zero then the price level is removed.

** Partitioning strategy
...

* Deploy
Make sure Kafka is running and is accessible to the Level4 container
i.e. they are on the same network. Refer to =compose.yml= for an
example compose file.

The following environment variables are available. Note: the variables
must be set for each level4 instance in a cluster, hence it is best to
use the Docker image and a compose file.

| Variable        | Description                                |  Default value |
|-----------------+--------------------------------------------+----------------|
| HOSTNAME        | The instance's hostname - each participant |          node1 |
|                 | in the cluster must have a unique name     |                |
|-----------------+--------------------------------------------+----------------|
| RPC_PORT        | gRPC server will listen on this port       |          50051 |
|-----------------+--------------------------------------------+----------------|
| KAFKA_ENDPOINTS | One or more Kafka brokers                  | 127.0.0.1:9093 |
|-----------------+--------------------------------------------+----------------|

** Interactive
...

#+BEGIN_SRC bash
  iex -S mix
#+END_SRC

** Docker
Docker images are available at
=registry.wsantos.net/tradingmachines/level4=.

#+BEGIN_SRC bash
  docker run -p 50051:50051 tradingmachines/level4:latest -d
#+END_SRC

** Compose
...

#+BEGIN_SRC bash
  docker compose up
#+END_SRC

* Develop
...

** building the container image
Remember to adjust =level4/config/config.exs= and
=level4/config/runtime.exs= before building the container image. Build
the image using the Makefile in =deploy/=.
